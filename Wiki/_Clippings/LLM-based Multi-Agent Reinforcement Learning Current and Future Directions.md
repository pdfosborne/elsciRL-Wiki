---
cite: "sun2024llm"
title: "LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions"
url: "https://arxiv.org/abs/2405.11106"
authors:
  - "Sun"
  - "Chuanneng"
  - "Huang"
  - "Songjun"
  - "Pompili"
  - "Dario"
publisher: "arXiv"
site: "arxiv"
published: 17/05/2024
year: 2024
created: 2025-06-11
description: "Surveys LLM-based MARL, focusing on cooperative tasks, communication, and human-in-the-loop scenarios."
tags:
  - "LLM"
  - "MARL"
  - "ReinforcementLearning"
  - "MultiAgentSystems"
  - "AI"
type: "ArXiv"
BibTeX (AI Generated): "@misc{sun2024llm,  author = {Sun, Chuanneng and Huang, Songjun and Pompili, Dario},  title = {LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions},  year = {2024},  eprint = {2405.11106},  archivePrefix = {arXiv},  primaryClass = {cs.AI}}"
citations:
---
# Summary

This paper surveys LLM-based single-agent and multi-agent RL frameworks and provides potential research directions, focusing on cooperative tasks and communication among agents, including human-in/on-the-loop scenarios.

----
# Article

LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions

In recent years, Large Language Models (LLMs) have demonstrated significant capabilities in various tasks, including question answering, arithmetic problem-solving, and poem writing.
Research on LLM-as-an-agent has shown that LLMs can be applied to Reinforcement Learning (RL) and achieve decent results. However, extending LLM-based RL to Multi-Agent Systems (MAS) is not trivial, as many aspects, such as coordination and communication between agents, are not considered in single-agent RL frameworks.
To inspire more research on LLM-based MARL, this letter surveys existing LLM-based single-agent and multi-agent RL frameworks and provides potential research directions for future research. The focus is on cooperative tasks of multiple agents with a common goal and communication among them. It also considers human-in/on-the-loop scenarios enabled by the language component in the framework.
